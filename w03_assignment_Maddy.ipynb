{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b208d4-57c3-498d-8a40-441c6b41646d",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "The task is to build and train a classifier given a labeled dataset and then use it to infer the labels of a given unlabeled evaluation dataset. \n",
    "\n",
    "You will find the training and evaluation data on canvas.\n",
    "\n",
    "Here's the training data: TrainOnMe-2.csv \n",
    "\n",
    "Here's the evaluation data: EvaluateOnMe-2.csv \n",
    "\n",
    "Here's the ground truth: EvaluationGT-2.csv\n",
    "\n",
    "You can use whatever python libraries you like! The steps below are suggestions, but feel free to try any other techniques we discussed in class.\n",
    "\n",
    "You can submit the predicted labels by uploading them in csv format, which will then be compared to the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea46c93-5d7d-4797-bbbe-4cdd7524e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /home/devel/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from seaborn) (1.26.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/homl3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3cf9a5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# For feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# For min-max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# For encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Some models you can try\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeca27-8629-4941-86c1-2d78c66ac582",
   "metadata": {},
   "source": [
    "## Load the training and evaluation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25826ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read datasets\n",
    "df = pd.read_csv('TrainOnMe-2.csv')\n",
    "eval_df = pd.read_csv('EvaluateOnMe-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc8de1-a994-4756-9989-d3f4b0de1f0d",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c95776a-27af-4777-8128-a1e9abf94a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1. Impute NA values\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy = \"median\")\n",
    "numerical_data = df.select_dtypes(include = [\"float64\"])\n",
    "numerical_data_imputed = numerical_imputer.fit_transform(numerical_data)\n",
    "numerical_data_imputed_df = pd.DataFrame(numerical_data_imputed)\n",
    "\n",
    "categorical_imputer = SimpleImputer(strategy = \"most_frequent\")\n",
    "categorical_data = df.select_dtypes(include = [\"object\"])\n",
    "categorical_data_imputed = categorical_imputer.fit_transform(categorical_data)\n",
    "categorical_data_imputed_df = pd.DataFrame(categorical_data_imputed)\n",
    "\n",
    "na_replaced_df = pd.concat([categorical_data_imputed_df, numerical_data_imputed_df], axis = 1)\n",
    "na_replaced_df.columns = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\"]\n",
    "\n",
    "# 2. Split the training data into features and labels\n",
    "\n",
    "features = na_replaced_df.drop(\"1\", axis = 1)\n",
    "numerical_features_df = pd.DataFrame(features.select_dtypes(include = [\"float64\"]))\n",
    "categorical_features_df = pd.DataFrame(features.select_dtypes(include = [\"object\"]))\n",
    "labels_prepared = na_replaced_df[\"1\"].copy()\n",
    "\n",
    "# 3. Encode categorical data\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "categorical_features_encoded = one_hot_encoder.fit_transform(categorical_features_df)\n",
    "categorical_features_encoded_df = pd.DataFrame(categorical_features_encoded.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad60bf-a533-4340-aabb-3d7a5c466e61",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "## Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ccf3fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to remove numerical outliers from training data to improve performance\n",
    "# There are different ways to do this but one way could be to use stats.zscore\n",
    "\n",
    "z_scores = stats.zscore(numerical_features_df)\n",
    "outlier_threshold = 3.0\n",
    "numerical_outliers = np.abs(z_scores) > outlier_threshold\n",
    "filtered_numerical_features = numerical_features_df[~ numerical_outliers]\n",
    "outliers_removed_numerical_features_imputed = numerical_imputer.fit_transform(filtered_numerical_features)\n",
    "outliers_removed_numerical_features_imputed_df = pd.DataFrame(outliers_removed_numerical_features_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933a70d-7f5c-46cf-b278-536053c42322",
   "metadata": {},
   "source": [
    "## Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a5a446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your features\n",
    "# You can try both standardscaler and minmaxscaler and see which works better\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#standard_scaler = StandardScaler()\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "numerical_features_scaled = min_max_scaler.fit_transform(outliers_removed_numerical_features_imputed_df)\n",
    "numerical_features_scaled_df = pd.DataFrame(numerical_features_scaled)\n",
    "\n",
    "# Prepare finalized features\n",
    "features_prepared = pd.concat([categorical_features_encoded_df, numerical_features_scaled_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f9ee0-f87c-4750-a328-dbdc9071fb07",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b35ae-3de7-4044-a59f-831a519ba36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could try to apply SelectKBest class to extract the most useful features (this is optional but MIGHT improve accuracy)\n",
    "# Remove whichever features that are not useful\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1dcc6-5f53-478d-9660-95368b4db961",
   "metadata": {},
   "source": [
    "## Split your data to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ed4f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_prepared, labels_prepared, \n",
    "                                                    train_size = 0.9, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cbcb0-c8ff-4d43-ab10-6c1e7d3aa0be",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "* You can try models other than the models listed below\n",
    "* You can try different hyperparameters\n",
    "* Evaluate your model using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c68ffb0a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5445544554455446\n",
      "0.41 accuracy with a standard deviation of 0.12\n"
     ]
    }
   ],
   "source": [
    "# Try linear SVM classifier\n",
    "linear = SVC(kernel = \"linear\", C = 0.5).fit(X_train, y_train)\n",
    "print(linear.score(X_test, y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(linear, X_test,y_test, cv = 5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d53115ce",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504950495049505\n",
      "0.60 accuracy with a standard deviation of 0.15\n"
     ]
    }
   ],
   "source": [
    "#Try decision tree classifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = \"gini\").fit(X_train, y_train)\n",
    "print(decision_tree.score(X_test,y_test))\n",
    "\n",
    "# Evaluate using cross-validation\n",
    "scores = cross_val_score(decision_tree, X_test, y_test, cv = 10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01507d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742574257425742\n",
      "0.51 accuracy with a standard deviation of 0.16\n"
     ]
    }
   ],
   "source": [
    "#Try random forest classifier\n",
    "random_forest = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(random_forest.score(X_test,y_test))\n",
    "\n",
    "scores = cross_val_score(random_forest,X_test,y_test,cv=10)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3b68b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your best model to predict the labels for the evaluation set\n",
    "\n",
    "#best_model = DecisionTreeClassifier(criterion = \"gini\").fit(X_eval)\n",
    "#y_pred = best_model.predict(X_eval)\n",
    "#y_pred = decision_tree.predict()\n",
    "\n",
    "#print(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "e6eb50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions to a CSV and upload it to Canvas\n",
    "\n",
    "pd.DataFrame(y_pred).to_csv(\"file.txt\", index = False, header = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
